# For example:
multiprocessing: True
path_pretrained_models: './pretrained_models'
dataset:
    data_path: '/teamspace/studios/this_studio/data'
blip_v2_model_type: blip2-flan-t5-xxl  # Change to blip2-flan-t5-xl for smaller GPUs
blip_half_precision: True
# Add more changes here, following the same format as base_config.yaml
azure:
    deployment_name: gpt-4o-2024-11-20
    api_key: 
    api_base: 
    api_version: 

gpt3:                                               # GPT-3 configuration
    n_votes: 1                                      # Number of tries to use for GPT-3. Use with temperature > 0
    qa_prompt: ./prompts/gpt3/gpt3_qa.txt
    guess_prompt: ./prompts/gpt3/gpt3_process_guess.txt
    temperature: 0.                                 # Temperature for GPT-3. Almost deterministic if 0
    model: gpt-4o

codex:
    temperature: 0.                                 # Temperature for Codex. (Almost) deterministic if 0
    best_of: 1                                      # Number of tries to choose from. Use when temperature > 0
    max_tokens: 512                                 # Maximum number of tokens to generate for Codex
    prompt: ./prompts/chatapi.prompt                # Codex prompt file, which defines the API. (doesn't support video for now due to token limits)
    model: gpt-4o                          # Codex model to use. [code-davinci-002, gpt-3.5-turbo, gpt-4]. See openai.Model.list() for available models  